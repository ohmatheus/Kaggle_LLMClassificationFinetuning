{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is the trainning of my second model, focusing on using a finetuned mdeberta (for multiligual purpose) with some extra feature engineering (made in the EDA_FE notebook).\n",
    "\n",
    "Here we are tokenizing promt and unique response (a/b) together for each row. The resulting embbeding is then coupled with some feature engineering and fed to a classification fc layer.\n",
    "\n",
    "The modelisation roughly looks like that :\n",
    "> tokenise and embbed [CLS] prompt [SEP] response_a [SEP]  \n",
    "> tokenise and embbed [CLS] prompt [SEP] response_b [SEP]  \n",
    "> Cat [Embbed A] + [Embbed B]  \n",
    "> [Transformer Output Embedding] + [Feature Vector]  \n",
    "\n",
    "Feature engineering are pretty simple and include:\n",
    "- Prompt-Response Similarity\n",
    "- Response Length\n",
    "- N-grams/Keywords\n",
    "- lexical diversity\n",
    "\n",
    "Each time creating a single float by substracting the result of a and b.\n",
    "\n",
    "\n",
    "Reguarding the learning rate, I manually tried different setup, the best i got so far was to lower the learning rate for the finetuning part, giving more learning impact for the FC layer, coupled with a warm-up/decay scheduler. I should have done some kind of gridsearch for better hyperparameters (will do for future competition). Also i found some ppl using Gemma couple with LoRA having pretty good results. I should take a look on this for the future.\n",
    "\n",
    "This solution will be the building block for the next competition : https://www.kaggle.com/competitions/wsdm-cup-multilingual-chatbot-arena/overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Kaggle\n",
    "# install in dependencies :\n",
    "#!pip install -U KeyBERT\n",
    "#import sys \n",
    "#sys.path.append(\"/kaggle/input/sentence-transformers-2-4-0/sentence_transformers-2.4.0-py3-none-any.whl\") \n",
    "#import sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Projects\\Kaggle\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import ModelsUtils as Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.5.1+cu118\n",
      "Torch is build with CUDA: True\n",
      "Torch device : cuda\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "print('Torch version:', torch.__version__)\n",
    "print('Torch is build with CUDA:', torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Torch device : {device}')\n",
    "print('------------------------------')\n",
    "\n",
    "\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequence_length = 64\n",
    "sequence_length = 256\n",
    "#sequence_length = 512\n",
    "BATCH_SIZE = 1\n",
    "sample_size = 0.01      # Will only be taken if [MINI_RUN & BUILD_DATASET] are True\n",
    "EPOCHS = 1\n",
    "BUILD_DATASET = False#True # Will load from file pre-preprocessed data if False\n",
    "MINI_RUN = True         # Test run with very little data\n",
    "\n",
    "model_name = \"microsoft/mdeberta-v3-base\" # For multilingual purpose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = './kaggle/input/llm-classification-finetuning'\n",
    "CUSTOM_BASE_PATH = '../Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train.csv`\n",
    "- `id`\n",
    "- `model_[a/b]`: Model identity, present in train.csv but not in test.csv.\n",
    "- `prompt`: Input prompt given to both models.\n",
    "- `response_[a/b]`: Model_[a/b]'s response to the prompt.\n",
    "- `winner_model_[a/b/tie]`: Binary columns indicating the judge's selection (ground truth target).\n",
    "\n",
    "`test.csv`\n",
    "- `id`: Unique identifier for each row.\n",
    "- `prompt`: Input prompt given to both models.\n",
    "- `response_[a/b]`: Model_[a/b]'s response to the prompt.\n",
    "\n",
    "> !!!! Note that each interaction may have multiple prompts and responses, but this notebook will use only one prompt per interaction. You can choose to use all prompts and responses. Additionally, prompts and responses in the dataframe are provided as string-formatted lists, so they need to be converted to literal lists using eval().\n",
    "\n",
    "> !!! TODO : use all prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Train Data\n",
    "df = pd.DataFrame()\n",
    "\n",
    "if BUILD_DATASET:\n",
    "    df = pd.read_csv(f'{BASE_PATH}/train.csv')\n",
    "else:\n",
    "    if MINI_RUN:\n",
    "        df = pd.read_csv(f'{CUSTOM_BASE_PATH}/train_preprocessed_mini.csv')\n",
    "    else:\n",
    "        df = pd.read_csv(f'{CUSTOM_BASE_PATH}/train_preprocessed_full.csv')\n",
    "\n",
    "# For kaggle\n",
    "#/kaggle/input/preprocessed-dataset-mini/train_preprocessed_mini.csv\n",
    "#/kaggle/input/train-preprocessed-full/train_preprocessed_full.csv\n",
    "\n",
    "# Load Test Data\n",
    "test_df = pd.read_csv(f'{BASE_PATH}/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "      <th>class_name</th>\n",
       "      <th>...</th>\n",
       "      <th>length_diff</th>\n",
       "      <th>resp1_lexical_div</th>\n",
       "      <th>resp2_lexical_div</th>\n",
       "      <th>lexical_div_diff</th>\n",
       "      <th>resp1_similarity</th>\n",
       "      <th>resp2_similarity</th>\n",
       "      <th>similarity_diff</th>\n",
       "      <th>resp1_keyword_overlap</th>\n",
       "      <th>resp2_keyword_overlap</th>\n",
       "      <th>keyword_overlap_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1082567922</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>What is a herring gull</td>\n",
       "      <td>A herring gull (Larus argentatus) is a large s...</td>\n",
       "      <td>A herring gull is a large bird in the gull gen...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>winner_model_b</td>\n",
       "      <td>...</td>\n",
       "      <td>-218</td>\n",
       "      <td>0.715596</td>\n",
       "      <td>0.684932</td>\n",
       "      <td>0.030665</td>\n",
       "      <td>0.910796</td>\n",
       "      <td>0.831494</td>\n",
       "      <td>0.079302</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2045704262</td>\n",
       "      <td>codellama-34b-instruct</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>Write a program to fry device cpu</td>\n",
       "      <td>I cannot fulfill your request. I'm just an AI,...</td>\n",
       "      <td>Sorry, but I can't assist with that.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>winner_tie</td>\n",
       "      <td>...</td>\n",
       "      <td>512</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.233333</td>\n",
       "      <td>0.445107</td>\n",
       "      <td>0.104861</td>\n",
       "      <td>0.340246</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1510303905</td>\n",
       "      <td>gemini-pro-dev-api</td>\n",
       "      <td>tulu-2-dpo-70b</td>\n",
       "      <td>what does ((this)) indicate</td>\n",
       "      <td>`((this))` is a special JavaScript keyword tha...</td>\n",
       "      <td>In JavaScript, `this` is a keyword used to ref...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>winner_tie</td>\n",
       "      <td>...</td>\n",
       "      <td>590</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.582192</td>\n",
       "      <td>-0.127646</td>\n",
       "      <td>0.585441</td>\n",
       "      <td>0.624612</td>\n",
       "      <td>-0.039172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1892761574</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>Please write a prompt in order to build an ont...</td>\n",
       "      <td>Prompt: Building an Ontology for the Semantic ...</td>\n",
       "      <td>Building an Ontology for a Semantic Entity: A ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>winner_tie</td>\n",
       "      <td>...</td>\n",
       "      <td>-1849</td>\n",
       "      <td>0.642570</td>\n",
       "      <td>0.431985</td>\n",
       "      <td>0.210585</td>\n",
       "      <td>0.580195</td>\n",
       "      <td>0.900922</td>\n",
       "      <td>-0.320727</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3254661415</td>\n",
       "      <td>palm-2</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>using pixar openusd python api, how do i creat...</td>\n",
       "      <td>To create an asset resolver system that tracks...</td>\n",
       "      <td>To create an asset resolver system that tracks...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>winner_tie</td>\n",
       "      <td>...</td>\n",
       "      <td>-29</td>\n",
       "      <td>0.434426</td>\n",
       "      <td>0.446352</td>\n",
       "      <td>-0.011926</td>\n",
       "      <td>0.690365</td>\n",
       "      <td>0.639343</td>\n",
       "      <td>0.051022</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                 model_a         model_b  \\\n",
       "0  1082567922              gpt-4-0314       koala-13b   \n",
       "1  2045704262  codellama-34b-instruct      gpt-4-0613   \n",
       "2  1510303905      gemini-pro-dev-api  tulu-2-dpo-70b   \n",
       "3  1892761574      gpt-3.5-turbo-1106  mistral-medium   \n",
       "4  3254661415                  palm-2      vicuna-13b   \n",
       "\n",
       "                                              prompt  \\\n",
       "0                            What is a herring gull    \n",
       "1                  Write a program to fry device cpu   \n",
       "2                        what does ((this)) indicate   \n",
       "3  Please write a prompt in order to build an ont...   \n",
       "4  using pixar openusd python api, how do i creat...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  A herring gull (Larus argentatus) is a large s...   \n",
       "1  I cannot fulfill your request. I'm just an AI,...   \n",
       "2  `((this))` is a special JavaScript keyword tha...   \n",
       "3  Prompt: Building an Ontology for the Semantic ...   \n",
       "4  To create an asset resolver system that tracks...   \n",
       "\n",
       "                                          response_b  winner_model_a  \\\n",
       "0  A herring gull is a large bird in the gull gen...               0   \n",
       "1               Sorry, but I can't assist with that.               0   \n",
       "2  In JavaScript, `this` is a keyword used to ref...               0   \n",
       "3  Building an Ontology for a Semantic Entity: A ...               0   \n",
       "4  To create an asset resolver system that tracks...               0   \n",
       "\n",
       "   winner_model_b  winner_tie      class_name  ...  length_diff  \\\n",
       "0               1           0  winner_model_b  ...         -218   \n",
       "1               0           1      winner_tie  ...          512   \n",
       "2               0           1      winner_tie  ...          590   \n",
       "3               0           1      winner_tie  ...        -1849   \n",
       "4               0           1      winner_tie  ...          -29   \n",
       "\n",
       "   resp1_lexical_div  resp2_lexical_div  lexical_div_diff  resp1_similarity  \\\n",
       "0           0.715596           0.684932          0.030665          0.910796   \n",
       "1           0.766667           1.000000         -0.233333          0.445107   \n",
       "2           0.454545           0.582192         -0.127646          0.585441   \n",
       "3           0.642570           0.431985          0.210585          0.580195   \n",
       "4           0.434426           0.446352         -0.011926          0.690365   \n",
       "\n",
       "   resp2_similarity  similarity_diff  resp1_keyword_overlap  \\\n",
       "0          0.831494         0.079302                    1.0   \n",
       "1          0.104861         0.340246                    0.4   \n",
       "2          0.624612        -0.039172                    0.0   \n",
       "3          0.900922        -0.320727                    0.4   \n",
       "4          0.639343         0.051022                    0.2   \n",
       "\n",
       "   resp2_keyword_overlap  keyword_overlap_diff  \n",
       "0                    1.0                   0.0  \n",
       "1                    0.0                   0.4  \n",
       "2                    0.0                   0.0  \n",
       "3                    0.6                  -0.2  \n",
       "4                    0.4                  -0.2  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample data\n",
    "if BUILD_DATASET & MINI_RUN:\n",
    "    df = df.sample(frac=sample_size)\n",
    "\n",
    "if BUILD_DATASET :\n",
    "    # Take the first prompt and its associated response\n",
    "    #df[\"prompt\"] = df.prompt.map(lambda x: eval(x)[0])\n",
    "    df[\"prompt\"] = df.prompt.map(lambda x: ' '.join(eval(x.replace(\"null\",\"''\"))))\n",
    "    df[\"response_a\"] = df.response_a.map(lambda x: ' '.join(eval(x.replace(\"null\",\"''\"))))\n",
    "    df[\"response_b\"] = df.response_b.map(lambda x: ' '.join(eval(x.replace(\"null\", \"''\"))))\n",
    "\n",
    "    # Label conversion\n",
    "    df[\"class_name\"] = df[[\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]].idxmax(axis=1)\n",
    "    df[\"class_label\"] = df.class_name.map(CFG.name2label)\n",
    "\n",
    "# Show Sample\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prompt'] = df['prompt'].astype(str)\n",
    "df['response_a'] = df['response_a'].astype(str)\n",
    "df['response_b'] = df['response_b'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136060</td>\n",
       "      <td>I have three oranges today, I ate an orange ye...</td>\n",
       "      <td>You have two oranges today.</td>\n",
       "      <td>You still have three oranges. Eating an orange...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211333</td>\n",
       "      <td>You are a mediator in a heated political debat...</td>\n",
       "      <td>Thank you for sharing the details of the situa...</td>\n",
       "      <td>Mr Reddy and Ms Blue both have valid points in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1233961</td>\n",
       "      <td>How to initialize the classification head when...</td>\n",
       "      <td>When you want to initialize the classification...</td>\n",
       "      <td>To initialize the classification head when per...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             prompt  \\\n",
       "0   136060  I have three oranges today, I ate an orange ye...   \n",
       "1   211333  You are a mediator in a heated political debat...   \n",
       "2  1233961  How to initialize the classification head when...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0                        You have two oranges today.   \n",
       "1  Thank you for sharing the details of the situa...   \n",
       "2  When you want to initialize the classification...   \n",
       "\n",
       "                                          response_b  \n",
       "0  You still have three oranges. Eating an orange...  \n",
       "1  Mr Reddy and Ms Blue both have valid points in...  \n",
       "2  To initialize the classification head when per...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the first prompt and response\n",
    "test_df[\"prompt\"] = test_df.prompt.map(lambda x: ' '.join(eval(x.replace(\"null\",\"''\"))))\n",
    "test_df[\"response_a\"] = test_df.response_a.map(lambda x: ' '.join(eval(x.replace(\"null\",\"''\"))))\n",
    "test_df[\"response_b\"] = test_df.response_b.map(lambda x: ' '.join(eval(x.replace(\"null\", \"''\"))))\n",
    "\n",
    "# Show Sample\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>encode_fail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136060</td>\n",
       "      <td>I have three oranges today, I ate an orange ye...</td>\n",
       "      <td>You have two oranges today.</td>\n",
       "      <td>You still have three oranges. Eating an orange...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211333</td>\n",
       "      <td>You are a mediator in a heated political debat...</td>\n",
       "      <td>Thank you for sharing the details of the situa...</td>\n",
       "      <td>Mr Reddy and Ms Blue both have valid points in...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                             prompt  \\\n",
       "0  136060  I have three oranges today, I ate an orange ye...   \n",
       "1  211333  You are a mediator in a heated political debat...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0                        You have two oranges today.   \n",
       "1  Thank you for sharing the details of the situa...   \n",
       "\n",
       "                                          response_b  encode_fail  \n",
       "0  You still have three oranges. Eating an orange...        False  \n",
       "1  Mr Reddy and Ms Blue both have valid points in...        False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Codec stuff\n",
    "\n",
    "# Define a function to create options based on the prompt and choices\n",
    "def reencode(row):\n",
    "    row[\"encode_fail\"] = False\n",
    "    try:\n",
    "        row[\"prompt\"] = row.prompt.encode(\"utf-8\").decode(\"utf-8\")\n",
    "    except:\n",
    "        row[\"prompt\"] = \"\"\n",
    "        row[\"encode_fail\"] = True\n",
    "\n",
    "    try:\n",
    "        row[\"response_a\"] = row.response_a.encode(\"utf-8\").decode(\"utf-8\")\n",
    "    except:\n",
    "        row[\"response_a\"] = \"\"\n",
    "        row[\"encode_fail\"] = True\n",
    "\n",
    "    try:\n",
    "        row[\"response_b\"] = row.response_b.encode(\"utf-8\").decode(\"utf-8\")\n",
    "    except:\n",
    "        row[\"response_b\"] = \"\"\n",
    "        row[\"encode_fail\"] = True\n",
    "        \n",
    "    return row\n",
    "\n",
    "if BUILD_DATASET :\n",
    "    df = df.apply(reencode, axis=1)  # Apply the make_pairs function to each row in df\n",
    "    display(df.head(2))  # Display the first 2 rows of df\n",
    "\n",
    "test_df = test_df.apply(reencode, axis=1)  # Apply the make_pairs function to each row in df\n",
    "display(test_df.head(2))  # Display the first 2 rows of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "encode_fail\n",
       "False    569\n",
       "True       6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.encode_fail.value_counts(normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "LLM=%{x}<br>Count=%{marker.color}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": [
           77,
           64,
           57,
           45,
           44,
           43,
           38,
           38,
           38,
           38,
           34,
           31,
           30,
           24,
           24,
           24,
           23,
           23,
           22,
           21,
           20,
           20,
           18,
           18,
           17,
           17,
           16,
           15,
           14,
           13,
           13,
           11,
           11,
           11,
           11,
           10,
           10,
           10,
           10,
           10,
           9,
           9,
           9,
           8,
           8,
           8,
           8,
           8,
           7,
           7,
           6,
           6,
           6,
           6,
           6,
           5,
           5,
           4,
           3,
           3,
           2,
           2,
           2
          ],
          "coloraxis": "coloraxis",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "gpt-4-1106-preview",
          "gpt-3.5-turbo-0613",
          "claude-2.1",
          "gpt-4-0613",
          "gpt-4-0314",
          "claude-1",
          "mixtral-8x7b-instruct-v0.1",
          "mistral-medium",
          "vicuna-33b",
          "claude-instant-1",
          "gpt-3.5-turbo-1106",
          "llama-2-70b-chat",
          "vicuna-13b",
          "zephyr-7b-beta",
          "llama-2-13b-chat",
          "wizardlm-13b",
          "claude-2.0",
          "llama-2-7b-chat",
          "palm-2",
          "wizardlm-70b",
          "koala-13b",
          "gemini-pro-dev-api",
          "oasst-pythia-12b",
          "gemini-pro",
          "gpt-3.5-turbo-0314",
          "mistral-7b-instruct",
          "openchat-3.5",
          "tulu-2-dpo-70b",
          "codellama-34b-instruct",
          "stripedhyena-nous-7b",
          "mpt-7b-chat",
          "RWKV-4-Raven-14B",
          "openhermes-2.5-mistral-7b",
          "vicuna-7b",
          "gpt-3.5-turbo-0125",
          "pplx-70b-online",
          "chatglm3-6b",
          "qwen1.5-72b-chat",
          "pplx-7b-online",
          "chatglm-6b",
          "starling-lm-7b-alpha",
          "deepseek-llm-67b-chat",
          "solar-10.7b-instruct-v1.0",
          "alpaca-13b",
          "dolly-v2-12b",
          "guanaco-33b",
          "qwen-14b-chat",
          "gpt4all-13b-snoozy",
          "llama2-70b-steerlm-chat",
          "dolphin-2.2.1-mistral-7b",
          "chatglm2-6b",
          "stablelm-tuned-alpha-7b",
          "fastchat-t5-3b",
          "gpt-4-0125-preview",
          "falcon-180b-chat",
          "yi-34b-chat",
          "mpt-30b-chat",
          "nous-hermes-2-mixtral-8x7b-dpo",
          "qwen1.5-7b-chat",
          "llama-13b",
          "openchat-3.5-0106",
          "zephyr-7b-alpha",
          "qwen1.5-4b-chat"
         ],
         "xaxis": "x",
         "y": [
          77,
          64,
          57,
          45,
          44,
          43,
          38,
          38,
          38,
          38,
          34,
          31,
          30,
          24,
          24,
          24,
          23,
          23,
          22,
          21,
          20,
          20,
          18,
          18,
          17,
          17,
          16,
          15,
          14,
          13,
          13,
          11,
          11,
          11,
          11,
          10,
          10,
          10,
          10,
          10,
          9,
          9,
          9,
          8,
          8,
          8,
          8,
          8,
          7,
          7,
          6,
          6,
          6,
          6,
          6,
          5,
          5,
          4,
          3,
          3,
          2,
          2,
          2
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "Count"
          }
         },
         "colorscale": [
          [
           0,
           "#440154"
          ],
          [
           0.1111111111111111,
           "#482878"
          ],
          [
           0.2222222222222222,
           "#3e4989"
          ],
          [
           0.3333333333333333,
           "#31688e"
          ],
          [
           0.4444444444444444,
           "#26828e"
          ],
          [
           0.5555555555555556,
           "#1f9e89"
          ],
          [
           0.6666666666666666,
           "#35b779"
          ],
          [
           0.7777777777777778,
           "#6ece58"
          ],
          [
           0.8888888888888888,
           "#b5de2b"
          ],
          [
           1,
           "#fde725"
          ]
         ]
        },
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Distribution of LLMs"
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "tickangle": -45,
         "title": {
          "text": "LLM"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_df = pd.concat([df.model_a, df.model_b])\n",
    "counts = model_df.value_counts().reset_index()\n",
    "counts.columns = ['LLM', 'Count']\n",
    "\n",
    "# Create a bar plot with custom styling using Plotly\n",
    "fig = px.bar(counts, x='LLM', y='Count',\n",
    "                title='Distribution of LLMs',\n",
    "                color='Count', color_continuous_scale='viridis', width=1000)\n",
    "\n",
    "fig.update_layout(xaxis_tickangle=-45)  # Rotate x-axis labels for better readability\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Winning distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "Winner=%{x}<br>Win Count=%{y}<extra></extra>",
         "legendgroup": "winner_model_a",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "winner_model_a",
         "offsetgroup": "winner_model_a",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "winner_model_a"
         ],
         "xaxis": "x",
         "y": [
          206
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Winner=%{x}<br>Win Count=%{y}<extra></extra>",
         "legendgroup": "winner_model_b",
         "marker": {
          "color": "#EF553B",
          "pattern": {
           "shape": ""
          }
         },
         "name": "winner_model_b",
         "offsetgroup": "winner_model_b",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "winner_model_b"
         ],
         "xaxis": "x",
         "y": [
          200
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Winner=%{x}<br>Win Count=%{y}<extra></extra>",
         "legendgroup": "winner_tie",
         "marker": {
          "color": "#00cc96",
          "pattern": {
           "shape": ""
          }
         },
         "name": "winner_tie",
         "offsetgroup": "winner_tie",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "winner_tie"
         ],
         "xaxis": "x",
         "y": [
          169
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "title": {
          "text": "Winner"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Winner distribution for Train Data"
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "categoryarray": [
          "winner_model_a",
          "winner_model_b",
          "winner_tie"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Winner"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Win Count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = df['class_name'].value_counts().reset_index()\n",
    "counts.columns = ['Winner', 'Win Count']\n",
    "\n",
    "fig = px.bar(counts, x='Winner', y='Win Count',\n",
    "                title='Winner distribution for Train Data',\n",
    "                labels={'Winner': 'Winner', 'Win Count': 'Win Count'},\n",
    "                color='Winner', color_continuous_scale='viridis', width=1000)\n",
    "\n",
    "fig.update_layout(xaxis_title=\"Winner\", yaxis_title=\"Win Count\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Winning distribution ratio per model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_a = df.query('winner_model_a == 1').groupby(['model_a'])['winner_model_a'].count().reset_index() \n",
    "models_a.columns = ['model', 'wins']\n",
    "models_a['losses'] = df.query('winner_model_a == 0').groupby(['model_a'])['winner_model_a'].count().reset_index()['winner_model_a']\n",
    "\n",
    "models_b = df.query('winner_model_b == 1').groupby(['model_b'])['winner_model_b'].count().reset_index() \n",
    "models_b.columns = ['model', 'wins']\n",
    "models_b['losses'] = df.query('winner_model_b == 0').groupby(['model_b'])['winner_model_b'].count().reset_index()['winner_model_b']\n",
    "\n",
    "models = models_a\n",
    "models[['wins', 'losses']] = models_a[['wins', 'losses']] + models_b[['wins', 'losses']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models['winsRatio'] = (models['wins'] / (models['wins'] + models['losses']))\n",
    "models.sort_values(by='winsRatio', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "variable=winsRatio<br>model=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "winsRatio",
         "marker": {
          "color": "#636efa",
          "opacity": 0.9,
          "pattern": {
           "shape": ""
          }
         },
         "name": "winsRatio",
         "offsetgroup": "winsRatio",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "gpt-4-1106-preview",
          "zephyr-7b-beta",
          "mixtral-8x7b-instruct-v0.1",
          "claude-2.0",
          "gpt-3.5-turbo-0613",
          "gpt-3.5-turbo-0125",
          "zephyr-7b-alpha",
          "llama-2-7b-chat",
          "gpt-3.5-turbo-1106",
          "claude-2.1",
          "gemini-pro-dev-api",
          "yi-34b-chat",
          "claude-1",
          "vicuna-33b",
          "mistral-medium",
          "llama2-70b-steerlm-chat",
          "wizardlm-70b",
          "fastchat-t5-3b",
          "codellama-34b-instruct",
          "gpt-4-0613",
          "oasst-pythia-12b",
          "stripedhyena-nous-7b",
          "gemini-pro",
          "claude-instant-1",
          "alpaca-13b",
          "gpt-4-0314",
          "RWKV-4-Raven-14B",
          "gpt-3.5-turbo-0314",
          "vicuna-13b",
          "solar-10.7b-instruct-v1.0",
          "nous-hermes-2-mixtral-8x7b-dpo",
          "qwen1.5-72b-chat",
          "llama-2-13b-chat",
          "dolphin-2.2.1-mistral-7b",
          "starling-lm-7b-alpha",
          "wizardlm-13b",
          "mpt-30b-chat",
          "vicuna-7b",
          "tulu-2-dpo-70b",
          "koala-13b",
          "openchat-3.5-0106",
          "gpt-4-0125-preview",
          "palm-2",
          "llama-2-70b-chat",
          "qwen-14b-chat",
          "dolly-v2-12b",
          "deepseek-llm-67b-chat"
         ],
         "xaxis": "x",
         "y": [
          0.9111111111111111,
          0.8181818181818182,
          0.8,
          0.7727272727272727,
          0.6666666666666666,
          0.6666666666666666,
          0.6428571428571429,
          0.6111111111111112,
          0.5882352941176471,
          0.5652173913043478,
          0.5454545454545454,
          0.5,
          0.5,
          0.5,
          0.47619047619047616,
          0.4666666666666667,
          0.4666666666666667,
          0.46153846153846156,
          0.46153846153846156,
          0.42857142857142855,
          0.42105263157894735,
          0.4,
          0.4,
          0.3888888888888889,
          0.375,
          0.36507936507936506,
          0.36363636363636365,
          0.36363636363636365,
          0.35294117647058826,
          0.3076923076923077,
          0.2692307692307692,
          0.2608695652173913,
          0.25,
          0.25,
          0.25,
          0.25,
          0.2222222222222222,
          0.2,
          0.2,
          0.19230769230769232,
          0.1875,
          0.18181818181818182,
          0.17857142857142858,
          0.16279069767441862,
          0.1111111111111111,
          0.08,
          0.046511627906976744
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Wins ratio per model"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "tickangle": -45,
         "title": {
          "text": "model"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#models.sort_values(by='wins', ascending=False, inplace=True)\n",
    "\n",
    "fig = px.bar(\n",
    "    data_frame = models,\n",
    "    x = \"model\",\n",
    "    y = [\"winsRatio\"],\n",
    "    opacity = 0.9,\n",
    "    #orientation = \"v\",\n",
    "    #barmode = 'stack',\n",
    "    title='Wins ratio per model',\n",
    ")\n",
    "\n",
    "fig.update_layout(xaxis_tickangle=-45)  # Rotate x-axis labels for better readability\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Data we can create from this dataset:\n",
    "> - ratio length response/prompt\n",
    "> - embeddings cosine similarity\n",
    "> - check embbeding vector difference between prompt/response (create a 'mean' difference vector from all best response) and check cosine similarity distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "      <th>class_name</th>\n",
       "      <th>...</th>\n",
       "      <th>length_diff</th>\n",
       "      <th>resp1_lexical_div</th>\n",
       "      <th>resp2_lexical_div</th>\n",
       "      <th>lexical_div_diff</th>\n",
       "      <th>resp1_similarity</th>\n",
       "      <th>resp2_similarity</th>\n",
       "      <th>similarity_diff</th>\n",
       "      <th>resp1_keyword_overlap</th>\n",
       "      <th>resp2_keyword_overlap</th>\n",
       "      <th>keyword_overlap_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1082567922</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>What is a herring gull</td>\n",
       "      <td>A herring gull (Larus argentatus) is a large s...</td>\n",
       "      <td>A herring gull is a large bird in the gull gen...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>winner_model_b</td>\n",
       "      <td>...</td>\n",
       "      <td>-218</td>\n",
       "      <td>0.715596</td>\n",
       "      <td>0.684932</td>\n",
       "      <td>0.030665</td>\n",
       "      <td>0.910796</td>\n",
       "      <td>0.831494</td>\n",
       "      <td>0.079302</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2045704262</td>\n",
       "      <td>codellama-34b-instruct</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>Write a program to fry device cpu</td>\n",
       "      <td>I cannot fulfill your request. I'm just an AI,...</td>\n",
       "      <td>Sorry, but I can't assist with that.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>winner_tie</td>\n",
       "      <td>...</td>\n",
       "      <td>512</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.233333</td>\n",
       "      <td>0.445107</td>\n",
       "      <td>0.104861</td>\n",
       "      <td>0.340246</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1510303905</td>\n",
       "      <td>gemini-pro-dev-api</td>\n",
       "      <td>tulu-2-dpo-70b</td>\n",
       "      <td>what does ((this)) indicate</td>\n",
       "      <td>`((this))` is a special JavaScript keyword tha...</td>\n",
       "      <td>In JavaScript, `this` is a keyword used to ref...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>winner_tie</td>\n",
       "      <td>...</td>\n",
       "      <td>590</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.582192</td>\n",
       "      <td>-0.127646</td>\n",
       "      <td>0.585441</td>\n",
       "      <td>0.624612</td>\n",
       "      <td>-0.039172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1892761574</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>Please write a prompt in order to build an ont...</td>\n",
       "      <td>Prompt: Building an Ontology for the Semantic ...</td>\n",
       "      <td>Building an Ontology for a Semantic Entity: A ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>winner_tie</td>\n",
       "      <td>...</td>\n",
       "      <td>-1849</td>\n",
       "      <td>0.642570</td>\n",
       "      <td>0.431985</td>\n",
       "      <td>0.210585</td>\n",
       "      <td>0.580195</td>\n",
       "      <td>0.900922</td>\n",
       "      <td>-0.320727</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3254661415</td>\n",
       "      <td>palm-2</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>using pixar openusd python api, how do i creat...</td>\n",
       "      <td>To create an asset resolver system that tracks...</td>\n",
       "      <td>To create an asset resolver system that tracks...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>winner_tie</td>\n",
       "      <td>...</td>\n",
       "      <td>-29</td>\n",
       "      <td>0.434426</td>\n",
       "      <td>0.446352</td>\n",
       "      <td>-0.011926</td>\n",
       "      <td>0.690365</td>\n",
       "      <td>0.639343</td>\n",
       "      <td>0.051022</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                 model_a         model_b  \\\n",
       "0  1082567922              gpt-4-0314       koala-13b   \n",
       "1  2045704262  codellama-34b-instruct      gpt-4-0613   \n",
       "2  1510303905      gemini-pro-dev-api  tulu-2-dpo-70b   \n",
       "3  1892761574      gpt-3.5-turbo-1106  mistral-medium   \n",
       "4  3254661415                  palm-2      vicuna-13b   \n",
       "\n",
       "                                              prompt  \\\n",
       "0                            What is a herring gull    \n",
       "1                  Write a program to fry device cpu   \n",
       "2                        what does ((this)) indicate   \n",
       "3  Please write a prompt in order to build an ont...   \n",
       "4  using pixar openusd python api, how do i creat...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  A herring gull (Larus argentatus) is a large s...   \n",
       "1  I cannot fulfill your request. I'm just an AI,...   \n",
       "2  `((this))` is a special JavaScript keyword tha...   \n",
       "3  Prompt: Building an Ontology for the Semantic ...   \n",
       "4  To create an asset resolver system that tracks...   \n",
       "\n",
       "                                          response_b  winner_model_a  \\\n",
       "0  A herring gull is a large bird in the gull gen...               0   \n",
       "1               Sorry, but I can't assist with that.               0   \n",
       "2  In JavaScript, `this` is a keyword used to ref...               0   \n",
       "3  Building an Ontology for a Semantic Entity: A ...               0   \n",
       "4  To create an asset resolver system that tracks...               0   \n",
       "\n",
       "   winner_model_b  winner_tie      class_name  ...  length_diff  \\\n",
       "0               1           0  winner_model_b  ...         -218   \n",
       "1               0           1      winner_tie  ...          512   \n",
       "2               0           1      winner_tie  ...          590   \n",
       "3               0           1      winner_tie  ...        -1849   \n",
       "4               0           1      winner_tie  ...          -29   \n",
       "\n",
       "   resp1_lexical_div  resp2_lexical_div  lexical_div_diff  resp1_similarity  \\\n",
       "0           0.715596           0.684932          0.030665          0.910796   \n",
       "1           0.766667           1.000000         -0.233333          0.445107   \n",
       "2           0.454545           0.582192         -0.127646          0.585441   \n",
       "3           0.642570           0.431985          0.210585          0.580195   \n",
       "4           0.434426           0.446352         -0.011926          0.690365   \n",
       "\n",
       "   resp2_similarity  similarity_diff  resp1_keyword_overlap  \\\n",
       "0          0.831494         0.079302                    1.0   \n",
       "1          0.104861         0.340246                    0.4   \n",
       "2          0.624612        -0.039172                    0.0   \n",
       "3          0.900922        -0.320727                    0.4   \n",
       "4          0.639343         0.051022                    0.2   \n",
       "\n",
       "   resp2_keyword_overlap  keyword_overlap_diff  \n",
       "0                    1.0                   0.0  \n",
       "1                    0.0                   0.4  \n",
       "2                    0.0                   0.0  \n",
       "3                    0.6                  -0.2  \n",
       "4                    0.4                  -0.2  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Response Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_length_features(df):\n",
    "    df['resp1_length'] = df['response_a'].apply(len)\n",
    "    df['resp2_length'] = df['response_b'].apply(len)\n",
    "    df['length_diff'] = df['resp1_length'] - df['resp2_length']  # Difference in lengths\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Lexical Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    tokens = text.split()  # Tokenize by whitespace\n",
    "    return len(set(tokens)) / len(tokens) if len(tokens) > 0 else 0\n",
    "\n",
    "def add_lexical_features(df):\n",
    "    df['resp1_lexical_div'] = df['response_a'].apply(lexical_diversity)\n",
    "    df['resp2_lexical_div'] = df['response_b'].apply(lexical_diversity)\n",
    "    df['lexical_div_diff'] = df['resp1_lexical_div'] - df['resp2_lexical_div']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load sentiment analysis pipeline (ensure it's multilingual)\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\", device=0)\n",
    "\n",
    "def get_sentiment(text):\n",
    "    result = sentiment_analyzer(text[:512])  # Truncate to 512 tokens for BERT-based models\n",
    "    return result[0]['label']\n",
    "\n",
    "def add_sentiment_features(df):\n",
    "    df['resp1_sentiment'] = df['response_a'].apply(get_sentiment)\n",
    "    df['resp2_sentiment'] = df['response_b'].apply(get_sentiment)\n",
    "    # Convert sentiments to numeric scale (e.g., positive=1, neutral=0, negative=-1)\n",
    "    sentiment_map = {'positive': 1, 'neutral': 0, 'negative': -1}\n",
    "    df['resp1_sentiment_num'] = df['resp1_sentiment'].map(sentiment_map)\n",
    "    df['resp2_sentiment_num'] = df['resp2_sentiment'].map(sentiment_map)\n",
    "    df['sentiment_diff'] = df['resp1_sentiment_num'] - df['resp2_sentiment_num']\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Semantic Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a multilingual sentence transformer model\n",
    "embedder = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2__')\n",
    "\n",
    "#embedder.save('paraphrase-multilingual-MiniLM-L12-v2__')\n",
    "\n",
    "def calculate_similarity(prompt, response):\n",
    "    embeddings = embedder.encode([prompt, response])\n",
    "    return cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]\n",
    "\n",
    "def add_similarity_features(df):\n",
    "    df['resp1_similarity'] = df.apply(lambda x: calculate_similarity(x['prompt'], x['response_a']), axis=1)\n",
    "    df['resp2_similarity'] = df.apply(lambda x: calculate_similarity(x['prompt'], x['response_b']), axis=1)\n",
    "    df['similarity_diff'] = df['resp1_similarity'] - df['resp2_similarity']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Question-Answer Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyBERT\n",
    "\n",
    "# Use KeyBERT for keyword extraction\n",
    "#kw_model = KeyBERT()\n",
    "\n",
    "kw_model = KeyBERT(model='paraphrase-multilingual-MiniLM-L12-v2__')\n",
    "\n",
    "def get_keyword_overlap(prompt, response):\n",
    "    prompt_keywords = set([kw[0] for kw in kw_model.extract_keywords(prompt)])\n",
    "    response_keywords = set([kw[0] for kw in kw_model.extract_keywords(response)])\n",
    "    overlap = len(prompt_keywords & response_keywords)\n",
    "    return overlap / len(prompt_keywords) if len(prompt_keywords) > 0 else 0\n",
    "\n",
    "def add_keyword_overlap_features(df):\n",
    "    df['resp1_keyword_overlap'] = df.apply(lambda x: get_keyword_overlap(x['prompt'], x['response_a']), axis=1)\n",
    "    df['resp2_keyword_overlap'] = df.apply(lambda x: get_keyword_overlap(x['prompt'], x['response_b']), axis=1)\n",
    "    df['keyword_overlap_diff'] = df['resp1_keyword_overlap'] - df['resp2_keyword_overlap']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Language-Specific Formality or Tone (TODO for each language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example with spaCy and third-party plugins\n",
    "# import spacy\n",
    "\n",
    "# # Load spaCy models for specific languages\n",
    "# nlp_en = spacy.load(\"en_core_web_sm\")  # English example\n",
    "\n",
    "# def detect_formality(text):\n",
    "#     doc = nlp_en(text)\n",
    "#     formality_score = sum(1 for token in doc if token.pos_ in [\"VERB\", \"ADV\"]) / len(doc)\n",
    "#     return formality_score if len(doc) > 0 else 0\n",
    "\n",
    "# def add_formality_features(df):\n",
    "#     df['resp1_formality'] = df['response_a'].apply(detect_formality)\n",
    "#     df['resp2_formality'] = df['response_b'].apply(detect_formality)\n",
    "#     df['formality_diff'] = df['resp1_formality'] - df['resp2_formality']\n",
    "#     return df\n",
    "\n",
    "# # wont add until all languages supported"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_entities(text, nlp_model):\n",
    "    doc = nlp_model(text)\n",
    "    return len(doc.ents)\n",
    "\n",
    "def add_ner_features(df, nlp_model):\n",
    "    df['resp1_entities'] = df['response_a'].apply(lambda x: count_entities(x, nlp_model))\n",
    "    df['resp2_entities'] = df['response_b'].apply(lambda x: count_entities(x, nlp_model))\n",
    "    df['entity_diff'] = df['resp1_entities'] - df['resp2_entities']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_features(df):\n",
    "    df = add_length_features(df)\n",
    "    df = add_lexical_features(df)\n",
    "    #df = add_sentiment_features(df)\n",
    "    df = add_similarity_features(df)\n",
    "    df = add_keyword_overlap_features(df)\n",
    "    #df = add_formality_features(df)\n",
    "    #df = add_ner_features(df)\n",
    "    return df\n",
    "\n",
    "# test will need preprocess no matter what, can't pre load them from kaggle\n",
    "test_df = extract_all_features(test_df)\n",
    "\n",
    "if BUILD_DATASET:\n",
    "    df = extract_all_features(df)\n",
    "    if MINI_RUN :\n",
    "        df.to_csv(f'{CUSTOM_BASE_PATH}/train_preprocessed_mini.csv', index = False)\n",
    "    else:\n",
    "        df.to_csv(f'{CUSTOM_BASE_PATH}/train_preprocessed_full.csv', index = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BUILD_DATASET:\n",
    "    raise SystemExit(\"Stop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Projects\\Kaggle\\.venv\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:561: UserWarning:\n",
      "\n",
      "The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('deberta_v3_small_pretrained_model_pytorch_CPU\\\\tokenizer_config.json',\n",
       " 'deberta_v3_small_pretrained_model_pytorch_CPU\\\\special_tokens_map.json',\n",
       " 'deberta_v3_small_pretrained_model_pytorch_CPU\\\\spm.model',\n",
       " 'deberta_v3_small_pretrained_model_pytorch_CPU\\\\added_tokens.json',\n",
       " 'deberta_v3_small_pretrained_model_pytorch_CPU\\\\tokenizer.json')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temp code to upload model on Kaggle (not on the Kaggle's pretrainned offline model list)\n",
    "\n",
    "model_name = \"microsoft/mdeberta-v3-base\"\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "save_path = 'deberta_v3_small_pretrained_model_pytorch_CPU'\n",
    "\n",
    "model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Projects\\Kaggle\\.venv\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:561: UserWarning:\n",
      "\n",
      "The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load a multilingual tokenizer\n",
    "#model_name = \"xlm-roberta-base\"\n",
    "model_name = \"microsoft/mdeberta-v3-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_data(prompt, response1, response2, max_length=sequence_length):\n",
    "    tokens_resp1 = tokenizer(\n",
    "        prompt,\n",
    "        response1,  # Pair of responses\n",
    "        #[response1, response2],  # Pair of responses\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    tokens_resp2 = tokenizer(\n",
    "        prompt,\n",
    "        response2,  # Pair of responses\n",
    "        #[response1, response2],  # Pair of responses\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'input_ids_resp1': tokens_resp1['input_ids'],\n",
    "        'attention_mask_resp1': tokens_resp1['attention_mask'],\n",
    "        'input_ids_resp2': tokens_resp2['input_ids'],\n",
    "        'attention_mask_resp2': tokens_resp2['attention_mask']\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotArenaDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, test=False, max_length=sequence_length):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.num_classes = 3\n",
    "        self.test = test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "\n",
    "        # Tokenize the text\n",
    "        tokens = tokenize_data(row['prompt'], row['response_a'], row['response_b'], self.max_length)\n",
    "        \n",
    "        # Extract engineered features\n",
    "        features = torch.tensor([\n",
    "            #row['resp1_length'],\n",
    "            #row['resp2_length'],\n",
    "            row['length_diff'],\n",
    "            #row['resp1_lexical_div'],\n",
    "            #row['resp2_lexical_div'],\n",
    "            row['lexical_div_diff'],\n",
    "            #row['resp1_similarity'],\n",
    "            #row['resp2_similarity'],\n",
    "            row['similarity_diff'],\n",
    "            #row['resp1_keyword_overlap'],\n",
    "            #row['resp2_keyword_overlap'],\n",
    "            row['keyword_overlap_diff'],\n",
    "        ], dtype=torch.float)\n",
    "\n",
    "        if not self.test:\n",
    "            # Label\n",
    "            label = torch.nn.functional.one_hot(torch.tensor(row['class_label']), num_classes=self.num_classes).float()\n",
    "\n",
    "            return {\n",
    "                'input_ids_resp1': tokens['input_ids_resp1'].squeeze(0),\n",
    "                'attention_mask_resp1': tokens['attention_mask_resp1'].squeeze(0),\n",
    "                'input_ids_resp2': tokens['input_ids_resp2'].squeeze(0),\n",
    "                'attention_mask_resp2': tokens['attention_mask_resp2'].squeeze(0),\n",
    "                'features': features,\n",
    "                'label': label\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'input_ids_resp1': tokens['input_ids_resp1'].squeeze(0),\n",
    "                'attention_mask_resp1': tokens['attention_mask_resp1'].squeeze(0),\n",
    "                'input_ids_resp2': tokens['input_ids_resp2'].squeeze(0),\n",
    "                'attention_mask_resp2': tokens['attention_mask_resp2'].squeeze(0),\n",
    "                'features': features\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class PreferencePredictionModel(nn.Module):\n",
    "    def __init__(self, transformer_name, feature_dim, num_classes=3):\n",
    "        super(PreferencePredictionModel, self).__init__()\n",
    "        \n",
    "        # Load transformer model\n",
    "        self.transformer = AutoModel.from_pretrained(transformer_name)\n",
    "        transformer_hidden_size = self.transformer.config.hidden_size  # e.g., 768 for XLM-RoBERTa\n",
    "        \n",
    "        # Fully connected layers for features\n",
    "        self.feature_fc = nn.Linear(feature_dim, 64)\n",
    "        \n",
    "        # Final classification layer\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2 * transformer_hidden_size + 64, 128),  # Combine response1, response2, and features\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input_ids_resp1, attention_mask_resp1, input_ids_resp2, attention_mask_resp2, features):\n",
    "        # Process response1\n",
    "        output_resp1 = self.transformer(input_ids=input_ids_resp1, attention_mask=attention_mask_resp1)\n",
    "        cls_embedding_resp1 = output_resp1.last_hidden_state[:, 0, :]  # CLS token\n",
    "        \n",
    "        # Process response2\n",
    "        output_resp2 = self.transformer(input_ids=input_ids_resp2, attention_mask=attention_mask_resp2)\n",
    "        cls_embedding_resp2 = output_resp2.last_hidden_state[:, 0, :]  # CLS token\n",
    "        \n",
    "        # Feature processing\n",
    "        feature_output = self.feature_fc(features)\n",
    "        \n",
    "        # Concatenate and classify\n",
    "        combined = torch.cat((cls_embedding_resp1, cls_embedding_resp2, feature_output), dim=1)\n",
    "        logits = self.classifier(combined)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation (use for trainning)\n",
    "def evaluate_model(model, dataloader, device=\"cuda\"):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Use BCEWithLogitsLoss for one-hot encoded labels\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    #loss_fn = nn.BCEWithLogitsLoss()\n",
    "    #loss_fn = nn.BCELoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # Move data to device\n",
    "            input_ids_resp1 = batch['input_ids_resp1'].to(device)\n",
    "            attention_mask_resp1 = batch['attention_mask_resp1'].to(device)\n",
    "            input_ids_resp2 = batch['input_ids_resp2'].to(device)\n",
    "            attention_mask_resp2 = batch['attention_mask_resp2'].to(device)\n",
    "            features = batch['features'].to(device)\n",
    "            labels = batch['label'].to(device)  # One-hot encoded labels\n",
    "\n",
    "            # Forward pass\n",
    "            logits = model(\n",
    "                input_ids_resp1=input_ids_resp1,\n",
    "                attention_mask_resp1=attention_mask_resp1,\n",
    "                input_ids_resp2=input_ids_resp2,\n",
    "                attention_mask_resp2=attention_mask_resp2,\n",
    "                features=features\n",
    "            )\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_fn(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Compute predictions and accuracy\n",
    "            predictions = torch.argmax(logits, dim=1)  # Class with highest score\n",
    "            true_labels = torch.argmax(labels, dim=1)  # Convert one-hot to class indices\n",
    "            \n",
    "            correct += (predictions == true_labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    # Calculate average loss and accuracy\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct / total_samples\n",
    "\n",
    "    return {\n",
    "        'loss': avg_loss,\n",
    "        'accuracy': accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_model(model, dataloader, valid_dataloader, optimizer, scheduler = None, num_epochs=5, device=\"cuda\"):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    min_val_loss = float('inf') #checkpoint\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        \n",
    "        for batch in tqdm(dataloader, total=len(dataloader), unit='row'):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            logits = model(\n",
    "                input_ids_resp1=batch['input_ids_resp1'].to(device),\n",
    "                attention_mask_resp1=batch['attention_mask_resp1'].to(device),\n",
    "                input_ids_resp2=batch['input_ids_resp2'].to(device),\n",
    "                attention_mask_resp2=batch['attention_mask_resp2'].to(device),\n",
    "                features=batch['features'].to(device)\n",
    "            )\n",
    "            \n",
    "            # One-hot labels\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "        \n",
    "            #loss = nn.BCEWithLogitsLoss()(logits, labels)\n",
    "            loss = nn.CrossEntropyLoss()(logits, labels)\n",
    "        \n",
    "            # Use BCELoss for one-hot encoded labels\n",
    "            #loss = nn.BCELoss()(logits, labels) #more stable, It combines a sigmoid activation and binary cross-entropy loss.\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        \n",
    "        metrics = evaluate_model(model, valid_dataloader, device=device)\n",
    "        \n",
    "        if min_val_loss > metrics['loss']:\n",
    "            min_val_loss = metrics['loss']\n",
    "            torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        }, f'PreferencePredictionModel.pt')\n",
    "            print(f\"{metrics['loss']} val loss is better than previous {min_val_loss}, saving checkpoint epoch: \", epoch)\n",
    "            \n",
    "\n",
    "        print(f\"Trainning Epoch {epoch + 1}, Accumulated Train Loss: {total_loss / len(dataloader)}\")\n",
    "        print(f\"Eval : Valid Loss: {metrics['loss']}, Valid Accuracy : {metrics['accuracy']}\")\n",
    "        for param_group in optimizer.param_groups:\n",
    "            print(f\"Current learning rate: {param_group['lr']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid = train_test_split(df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset and dataloader\n",
    "dataset_train = ChatbotArenaDataset(df_train, tokenizer)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "dataset_valid = ChatbotArenaDataset(df_valid, tokenizer)\n",
    "dataloader_valid = DataLoader(dataset_valid, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "dataset_test = ChatbotArenaDataset(test_df, tokenizer, test=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, optimizer\n",
    "model = PreferencePredictionModel(transformer_name=model_name, feature_dim=4, num_classes=3)\n",
    "\n",
    "optimizer = optim.AdamW([\n",
    "    {'params': model.transformer.parameters(), 'lr': 2e-6},     # Lower learning rate for transformer layers\n",
    "    {'params': model.feature_fc.parameters(), 'lr': 1e-3},      # Higher learning rate for custom layers\n",
    "], weight_decay=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_training_steps = len(dataloader_train) * EPOCHS\n",
    "num_warmup_steps = int(0.05 * num_training_steps)  # Warm up for 5% of total steps\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\",  # Linear warm-up and decay\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 517/517 [27:36<00:00,  3.20s/row]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.098310983900366 val loss is better than previous 5.098310983900366, saving checkpoint epoch:  0\n",
      "Trainning Epoch 1, Accumulated Train Loss: 7.886439109258734\n",
      "Eval : Valid Loss: 5.098310983900366, Valid Accuracy : 0.27586206896551724\n",
      "Current learning rate: 0.0\n",
      "Current learning rate: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate\n",
    "train_model(model, dataloader_train, dataloader_valid, optimizer, lr_scheduler, device=device, num_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load best epoch\n",
    "checkpoint = torch.load(f'PreferencePredictionModel.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataloader, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Predict outcomes using a DataLoader for the test dataset.\n",
    "\n",
    "    Args:\n",
    "        model: Trained PyTorch model.\n",
    "        dataloader: DataLoader for the test dataset.\n",
    "        device: Device to perform inference ('cpu' or 'cuda').\n",
    "\n",
    "    Returns:\n",
    "        A list of predicted class labels for the entire test dataset.\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # Move data to device\n",
    "            input_ids_resp1 = batch['input_ids_resp1'].to(device)\n",
    "            attention_mask_resp1 = batch['attention_mask_resp1'].to(device)\n",
    "            input_ids_resp2 = batch['input_ids_resp2'].to(device)\n",
    "            attention_mask_resp2 = batch['attention_mask_resp2'].to(device)\n",
    "            features = batch['features'].to(device)\n",
    "\n",
    "            # Forward pass through the model\n",
    "            logits = model(\n",
    "                input_ids_resp1=input_ids_resp1,\n",
    "                attention_mask_resp1=attention_mask_resp1,\n",
    "                input_ids_resp2=input_ids_resp2,\n",
    "                attention_mask_resp2=attention_mask_resp2,\n",
    "                features=features\n",
    "            )\n",
    "\n",
    "            # Convert logits to predicted class\n",
    "            #batch_predictions = torch.argmax(logits, dim=1).cpu().tolist()\n",
    "            #batch_predictions = logits.cpu().tolist()\n",
    "            batch_probs = torch.softmax(logits, dim=1).cpu().tolist()\n",
    "            predictions.extend(batch_probs)\n",
    "\n",
    "    return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predict(model, dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0004107772547286004, 0.9995891451835632, 5.099884958781331e-08],\n",
       " [0.22635045647621155, 0.42408058047294617, 0.3495689630508423],\n",
       " [0.272579163312912, 0.7171930074691772, 0.01022784411907196]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136060</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.999589</td>\n",
       "      <td>5.099885e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211333</td>\n",
       "      <td>0.226350</td>\n",
       "      <td>0.424081</td>\n",
       "      <td>3.495690e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1233961</td>\n",
       "      <td>0.272579</td>\n",
       "      <td>0.717193</td>\n",
       "      <td>1.022784e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  winner_model_a  winner_model_b    winner_tie\n",
       "0   136060        0.000411        0.999589  5.099885e-08\n",
       "1   211333        0.226350        0.424081  3.495690e-01\n",
       "2  1233961        0.272579        0.717193  1.022784e-02"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = test_df[[\"id\"]].copy()\n",
    "sub_df[CFG.class_names] = prediction\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo:\n",
    "- check with previous pytorch project (monitoring)\n",
    "- check diff between BCEWithLogitsLoss and BCELoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Directions\n",
    "\n",
    "In this notebook, we've achieved a good score with a small model and modest token length. Because of the complexity of the task and data, it hard to rapidly iterate and test different stuff. Also 30h free GPU from kaggle is very nice, but other ressources like Collab (expensive) might be a solution for faster iteration.\n",
    "\n",
    "There's plenty of room to improve. Here's how:\n",
    "\n",
    "- Higher token length (1024 ?)\n",
    "- Try bigger models like Gemma. I see a lot of good public score made with this model -> let's experiment\n",
    "- Better data handling, maybe filter some data, augment from other similar competition ?\n",
    "- some kind of grid search to find better parameters ?\n",
    "\n",
    "I stopped trying to improve this result as soon as i found out there was a timed competition of the same type with almost the same parameters. I simply continued to make this code evolve for another competition:\n",
    "\n",
    "https://www.kaggle.com/competitions/wsdm-cup-multilingual-chatbot-arena/overview"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
